{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree (DT) for multiclass DDoS attack detection. \n",
    "In this lab we train a DT with benign network traffic and four classes of DDoS attacks from the CIC-DDoS2019 dataset of the University of New Brunswick. The network traffic has been previously pre-processed in a way that packets are grouped in bi-directional traffic flows using the 5-tuple (source IP, destination IP, source Port, destination Port, protocol). Each flow is represented with 21 packet-header features computed from max 1000 packets:\n",
    "\n",
    "| Feature nr.         | Feature Name |\n",
    "|---------------------|---------------------|\n",
    "| 00 | timestamp (mean IAT) | \n",
    "| 01 | packet_length (mean)| \n",
    "| 02 | IP_flags_df (sum) |\n",
    "| 03 | IP_flags_mf (sum) |\n",
    "| 04 | IP_flags_rb (sum) | \n",
    "| 05 | IP_frag_off (sum) |\n",
    "| 06 | protocols (mean) |\n",
    "| 07 | TCP_length (mean) |\n",
    "| 08 | TCP_flags_ack (sum) |\n",
    "| 09 | TCP_flags_cwr (sum) |\n",
    "| 10 | TCP_flags_ece (sum) |\n",
    "| 11 | TCP_flags_fin (sum) |\n",
    "| 12 | TCP_flags_push (sum) |\n",
    "| 13 | TCP_flags_res (sum) |\n",
    "| 14 | TCP_flags_reset (sum) |\n",
    "| 15 | TCP_flags_syn (sum) |\n",
    "| 16 | TCP_flags_urg (sum) |\n",
    "| 17 | TCP_window_size (mean) |\n",
    "| 18 | UDP_length (mean) |\n",
    "| 19 | ICMP_type (mean) |\n",
    "| 20 | Packets (counter)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Course on Network Intrusion and Anomaly Detection with Deep Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from IPython.display import Image, display\n",
    "from util_functions import *\n",
    "\n",
    "OUTPUT_FILE = \"./ddos_tree\"\n",
    "DATASET_FOLDER = \"./DOS2019\"\n",
    "X_train, y_train = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5')\n",
    "\n",
    "feature_names = get_feature_names(flatten=True)\n",
    "target_names = ['benign', 'dns',  'syn', 'udplag', 'webddos'] #IMPORTANT: when adding new classes, maintain the alphabetical order\n",
    "target_names_full = ['benign', 'dns', 'ldap', 'mssql', 'netbios', 'ntp', 'portmap', 'snmp', 'ssdp', 'syn', 'tftp', 'udp', 'udplag', 'webddos'] # we use this to match class names with the class numbers returned by the DT\n",
    "\n",
    "X = X_train\n",
    "y = np.where(y_train==1)[1] \n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3) # other stopping paramters are min_samples_split and min_samples_leaf\n",
    "tree_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(\n",
    "    tree_clf,\n",
    "    out_file=OUTPUT_FILE + \".dot\",\n",
    "    feature_names=feature_names,\n",
    "    class_names=target_names,\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comvert the \"dot\" file into a png image\n",
    "os.system(\"dot -Tpng \" + OUTPUT_FILE + \".dot -o \" + OUTPUT_FILE + \".png\")\n",
    "display(Image(filename=OUTPUT_FILE + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Now, we use the trained decision tree to make prediction on unseen data (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_dataset(DATASET_FOLDER + \"/*\" + '-test.hdf5')\n",
    "y_test = np.where(y_test==1)[1] #from one-shot-encoding to numbers\n",
    "\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "\n",
    "for y_index in range(y_pred.shape[0]):\n",
    "    dt_result_string = \"\" if y_pred[y_index] == y_test[y_index] else \" <-- Mistake!!! Predicted \" + target_names_full[y_pred[y_index]] + \" instead of \" + target_names_full[y_test[y_index]]\n",
    "    print (\"Test sample \" + str(y_index) + \" - \" + \"Pred: \" + str(y_pred[y_index]) + \" Label: \" + str(y_test[y_index]) + dt_result_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the wrong predictions\n",
    "Decision Trees are intuitive, and their decisions are easy to interpret. Such models are often called *white box models*. In contrast, as we will see, Random Forests or neural networks are generally considered black box models.\n",
    "Let's check where the DT did wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_formatter = \"{:.2f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "                    \n",
    "for y_index in range(y_pred.shape[0]):\n",
    "    if y_pred[y_index] != y_test[y_index]:\n",
    "        print(\"Wrong sample n. \" + str(y_index) + \" (Predicted \" + target_names_full[y_pred[y_index]] + \" instead of \" + target_names_full[y_test[y_index]] + \")\")\n",
    "        for feature_index in range(len(feature_names)):\n",
    "            print (feature_names[feature_index] + \": \" + str(X_test[y_index][feature_index]))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy metrics\n",
    "Now we print the confusion matrix and the other accuracy metrics for this multiclass problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        tree_clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=target_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
